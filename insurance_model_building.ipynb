{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,BaggingClassifier,AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score,classification_report,confusion_matrix,accuracy_score,f1_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('ins3_train.csv')\n",
    "test=pd.read_csv('ins3_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Id</th>\n",
       "      <th>YearOfObservation</th>\n",
       "      <th>Insured_Period</th>\n",
       "      <th>Residential</th>\n",
       "      <th>Building_Painted</th>\n",
       "      <th>Building_Fenced</th>\n",
       "      <th>Garden</th>\n",
       "      <th>Settlement</th>\n",
       "      <th>Building Dimension</th>\n",
       "      <th>Building_Type</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>&gt;=10</th>\n",
       "      <th>paint_fence</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H14663</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>290.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H2037</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H3802</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>595.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H3834</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2840.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H5053</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer Id  YearOfObservation  Insured_Period  Residential  \\\n",
       "0      H14663               2013             1.0            0   \n",
       "1       H2037               2015             1.0            0   \n",
       "2       H3802               2014             1.0            0   \n",
       "3       H3834               2013             1.0            0   \n",
       "4       H5053               2014             1.0            0   \n",
       "\n",
       "   Building_Painted  Building_Fenced  Garden  Settlement  Building Dimension  \\\n",
       "0                 1                0     1.0           1               290.0   \n",
       "1                 0                1     0.0           0               490.0   \n",
       "2                 1                0     1.0           1               595.0   \n",
       "3                 0                0     1.0           1              2840.0   \n",
       "4                 0                1     0.0           0               680.0   \n",
       "\n",
       "   Building_Type  ...  3  4  5  6  7  8  9  >=10  paint_fence  month  \n",
       "0              1  ...  0  0  0  0  0  0  0     0            1     12  \n",
       "1              1  ...  0  1  0  0  0  0  0     0            0     12  \n",
       "2              1  ...  0  0  0  0  0  0  0     0            1     12  \n",
       "3              1  ...  0  0  0  0  0  0  0     0            0     12  \n",
       "4              1  ...  1  0  0  0  0  0  0     0            0     12  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer Id', 'YearOfObservation', 'Insured_Period', 'Residential',\n",
       "       'Building_Painted', 'Building_Fenced', 'Garden', 'Settlement',\n",
       "       'Building Dimension', 'Building_Type', 'Date_of_Occupancy', 'Geo_Code',\n",
       "       'Claim', '   .', '1', '2', '3', '4', '5', '6', '7', '8', '9', '>=10',\n",
       "       'paint_fence', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       H11920\n",
       "1       H11921\n",
       "2        H9805\n",
       "3        H7493\n",
       "4        H7494\n",
       "         ...  \n",
       "3064    H11583\n",
       "3065    H11720\n",
       "3066    H11721\n",
       "3067    H12408\n",
       "3068     H9021\n",
       "Name: Customer Id, Length: 3069, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id=test['Customer Id']\n",
    "test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop('Customer Id',axis=1)\n",
    "test=test.drop('Customer Id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.drop('Claim',axis=1)\n",
    "y=train.Claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CatBoostClassifier(n_estimators=800,eval_metric='AUC',max_depth=5,learning_rate=0.1,od_wait=50, \n",
    "                              subsample=0.9,bootstrap_type='Bernoulli',metric_period=20,\n",
    "                     #l2_leaf_reg=5,#bagging_temperature=0.85,random_strength=100,\n",
    "                     use_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6698251\tbest: 0.6698251 (0)\ttotal: 208ms\tremaining: 2m 46s\n",
      "20:\ttest: 0.7115447\tbest: 0.7115447 (20)\ttotal: 625ms\tremaining: 23.2s\n",
      "40:\ttest: 0.7139615\tbest: 0.7140037 (35)\ttotal: 858ms\tremaining: 15.9s\n",
      "60:\ttest: 0.7144937\tbest: 0.7144937 (60)\ttotal: 1.08s\tremaining: 13.1s\n",
      "80:\ttest: 0.7176865\tbest: 0.7189336 (70)\ttotal: 1.28s\tremaining: 11.3s\n",
      "100:\ttest: 0.7178998\tbest: 0.7189336 (70)\ttotal: 1.51s\tremaining: 10.4s\n",
      "120:\ttest: 0.7163432\tbest: 0.7189336 (70)\ttotal: 1.89s\tremaining: 10.6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7189335796\n",
      "bestIteration = 70\n",
      "\n",
      "Shrink model to first 71 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1248e0077c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, eval_set=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 30% validation and 70% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42) #0.15 bank40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6931422\ttest1: 0.6746810\tbest: 0.6746810 (0)\ttotal: 14.6ms\tremaining: 11.7s\n",
      "100:\ttest: 0.7747940\ttest1: 0.7024475\tbest: 0.7041135 (81)\ttotal: 1.63s\tremaining: 11.3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7041134985\n",
      "bestIteration = 81\n",
      "\n",
      "Shrink model to first 82 iterations.\n",
      "err:  0.7041134984908706\n",
      "0:\ttest: 0.6473000\ttest1: 0.6528848\tbest: 0.6528848 (0)\ttotal: 15.9ms\tremaining: 12.7s\n",
      "100:\ttest: 0.7669939\ttest1: 0.7298798\tbest: 0.7319945 (32)\ttotal: 1.48s\tremaining: 10.2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7319945412\n",
      "bestIteration = 32\n",
      "\n",
      "Shrink model to first 33 iterations.\n",
      "err:  0.7319945412345974\n",
      "0:\ttest: 0.6724916\ttest1: 0.6830082\tbest: 0.6830082 (0)\ttotal: 15.1ms\tremaining: 12.1s\n",
      "100:\ttest: 0.7641938\ttest1: 0.7239983\tbest: 0.7255865 (72)\ttotal: 1.3s\tremaining: 8.98s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7255864989\n",
      "bestIteration = 72\n",
      "\n",
      "Shrink model to first 73 iterations.\n",
      "err:  0.7255864988503544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\n",
    "errcb=[]\n",
    "y_pred_totcb=[]\n",
    "from sklearn.model_selection import KFold,StratifiedKFold, TimeSeriesSplit, GroupKFold\n",
    "fold=StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "i=1\n",
    "for train_index, test_index in fold.split(X,y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    m=CatBoostClassifier(n_estimators=800,eval_metric='AUC',max_depth=4,learning_rate=0.1,#reg_lambda=5,#5\n",
    "                              subsample=0.9,bootstrap_type='Bernoulli',#leaf_estimation_iterations=10,\n",
    "                    #l2_leaf_reg=5,#bagging_temperature=0.85,random_strength=100,\n",
    "                     use_best_model=True)\n",
    "    #CatBoostClassifier(n_estimators=1000,eval_metric='AUC',max_depth=5,learning_rate=0.1,reg_lambda=5,#5\n",
    "                              #subsample=0.9,bootstrap_type='Bernoulli',\n",
    "                    #l2_leaf_reg=5,#bagging_temperature=0.85,random_strength=100,\n",
    "                     #use_best_model=True)\n",
    "    m.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_test, y_test)], early_stopping_rounds=100,verbose=100)\n",
    "    preds=m.predict_proba(X_test)[:, 1]\n",
    "    print(\"err: \",roc_auc_score(y_test,preds))\n",
    "    errcb.append(roc_auc_score(y_test,preds))\n",
    "    p = m.predict_proba(test)[:, 1]\n",
    "    y_pred_totcb.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7205648461919408"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6600821\ttest1: 0.6385077\tbest: 0.6385077 (0)\ttotal: 16.4ms\tremaining: 16.4s\n",
      "100:\ttest: 0.7711234\ttest1: 0.6974987\tbest: 0.6982837 (22)\ttotal: 1.2s\tremaining: 10.7s\n",
      "200:\ttest: 0.8017679\ttest1: 0.6937025\tbest: 0.6997729 (129)\ttotal: 2.27s\tremaining: 9.01s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6997728835\n",
      "bestIteration = 129\n",
      "\n",
      "Shrink model to first 130 iterations.\n",
      "err:  0.6997728834832502\n",
      "0:\ttest: 0.6449946\ttest1: 0.6585204\tbest: 0.6585204 (0)\ttotal: 10.1ms\tremaining: 10.1s\n",
      "100:\ttest: 0.7590990\ttest1: 0.7314332\tbest: 0.7349037 (38)\ttotal: 1.41s\tremaining: 12.6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7349037245\n",
      "bestIteration = 38\n",
      "\n",
      "Shrink model to first 39 iterations.\n",
      "err:  0.7349037245116498\n",
      "0:\ttest: 0.6556830\ttest1: 0.6476476\tbest: 0.6476476 (0)\ttotal: 14.3ms\tremaining: 14.3s\n",
      "100:\ttest: 0.7641468\ttest1: 0.7311067\tbest: 0.7320198 (77)\ttotal: 1.26s\tremaining: 11.2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7320198234\n",
      "bestIteration = 77\n",
      "\n",
      "Shrink model to first 78 iterations.\n",
      "err:  0.7320198234016734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\n",
    "errcb1=[]\n",
    "y_pred_totcb1=[]\n",
    "from sklearn.model_selection import KFold,StratifiedKFold, TimeSeriesSplit\n",
    "fold=StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "i=1\n",
    "for train_index, test_index in fold.split(X,y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    m1=CatBoostClassifier(n_estimators=1000,eval_metric='AUC',max_depth=4,learning_rate=0.1,od_wait=50, reg_lambda=3,\n",
    "                              bootstrap_type='Bayesian',\n",
    "                     use_best_model=True)\n",
    "    m1.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_test, y_test)], early_stopping_rounds=100,verbose=100)\n",
    "    preds=m1.predict_proba(X_test)[:, 1]\n",
    "    print(\"err: \",roc_auc_score(y_test,preds))\n",
    "    errcb1.append(roc_auc_score(y_test,preds))\n",
    "    p1 = m1.predict_proba(test)[:, 1]\n",
    "    y_pred_totcb1.append(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7222321437988577"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errcb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"metrics\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:33:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.65507\tvalidation_1-logloss:0.65947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-logloss:0.37910\tvalidation_1-logloss:0.48562\n",
      "[137]\tvalidation_0-logloss:0.35355\tvalidation_1-logloss:0.49071\n",
      "err:  0.7319027177842706\n",
      "[09:33:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"metrics\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:33:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.65575\tvalidation_1-logloss:0.65510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\bryan\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\bryan\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-logloss:0.37440\tvalidation_1-logloss:0.47354\n",
      "[128]\tvalidation_0-logloss:0.35486\tvalidation_1-logloss:0.47706\n",
      "err:  0.7256241015211045\n",
      "[09:33:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"metrics\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:33:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.65639\tvalidation_1-logloss:0.65410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\bryan\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-logloss:0.38543\tvalidation_1-logloss:0.45602\n",
      "[133]\tvalidation_0-logloss:0.36657\tvalidation_1-logloss:0.46053\n",
      "err:  0.7132871411309442\n",
      "[09:33:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"metrics\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:33:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.65398\tvalidation_1-logloss:0.66137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\bryan\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-logloss:0.37276\tvalidation_1-logloss:0.53941\n",
      "[122]\tvalidation_0-logloss:0.36074\tvalidation_1-logloss:0.54390\n",
      "err:  0.6949319630598234\n",
      "[09:33:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"metrics\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:33:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.65421\tvalidation_1-logloss:0.65737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\bryan\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-logloss:0.37131\tvalidation_1-logloss:0.52309\n",
      "[120]\tvalidation_0-logloss:0.35673\tvalidation_1-logloss:0.52462\n",
      "err:  0.6824726971677091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\n",
    "errcb2=[]\n",
    "y_pred_totcb2=[]\n",
    "from sklearn.model_selection import KFold,StratifiedKFold, TimeSeriesSplit\n",
    "fold=KFold(n_splits=5)\n",
    "i=1\n",
    "for train_index, test_index in fold.split(X,y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    m2=XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=800, silent=True, metrics='auc',colsample_bylevel=0.8, reg_alpha=0.8)\n",
    "    m2.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_test, y_test)], early_stopping_rounds=100,verbose=100)\n",
    "    preds=m2.predict_proba(X_test)[:, 1]\n",
    "    print(\"err: \",roc_auc_score(y_test,preds))\n",
    "    errcb2.append(roc_auc_score(y_test,preds))\n",
    "    p2 = m2.predict_proba(test)[:, 1]\n",
    "    y_pred_totcb2.append(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7096437241327703"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(errcb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"Customer Id\": test_id, 'Claim': np.mean(y_pred_totcb, 0)}\n",
    "test_predictions = pd.DataFrame(data=d)\n",
    "test_predictions = test_predictions[[\"Customer Id\", 'Claim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.to_csv('in14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Id</th>\n",
       "      <th>Claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H11920</td>\n",
       "      <td>0.096764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H11921</td>\n",
       "      <td>0.085731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H9805</td>\n",
       "      <td>0.086794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H7493</td>\n",
       "      <td>0.148120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H7494</td>\n",
       "      <td>0.129505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer Id     Claim\n",
       "0      H11920  0.096764\n",
       "1      H11921  0.085731\n",
       "2       H9805  0.086794\n",
       "3       H7493  0.148120\n",
       "4       H7494  0.129505"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"Customer Id\": test_id, 'Claim': np.mean(y_pred_totcb1, 0)}\n",
    "test_predictioned = pd.DataFrame(data=d)\n",
    "test_predictioned = test_predictioned[[\"Customer Id\", 'Claim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Id</th>\n",
       "      <th>Claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H11920</td>\n",
       "      <td>0.096945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H11921</td>\n",
       "      <td>0.085889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H9805</td>\n",
       "      <td>0.076101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H7493</td>\n",
       "      <td>0.142849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H7494</td>\n",
       "      <td>0.126811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer Id     Claim\n",
       "0      H11920  0.096945\n",
       "1      H11921  0.085889\n",
       "2       H9805  0.076101\n",
       "3       H7493  0.142849\n",
       "4       H7494  0.126811"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictioned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"Customer Id\": test_id, 'Claim': np.mean(y_pred_totcb2, 0)}\n",
    "test_prediction = pd.DataFrame(data=d)\n",
    "test_prediction = test_prediction[[\"Customer Id\", 'Claim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Id</th>\n",
       "      <th>Claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H11920</td>\n",
       "      <td>0.096764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H11921</td>\n",
       "      <td>0.085731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H9805</td>\n",
       "      <td>0.086794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H7493</td>\n",
       "      <td>0.148120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H7494</td>\n",
       "      <td>0.129505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer Id     Claim\n",
       "0      H11920  0.096764\n",
       "1      H11921  0.085731\n",
       "2       H9805  0.086794\n",
       "3       H7493  0.148120\n",
       "4       H7494  0.129505"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('in14.csv')\n",
    "b = pd.read_csv('i2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9810561365970896"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['Claim'].corr(a['Claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9708649052297122"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions['Claim'].corr(test_prediction['Claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions['Claim'] = (a['Claim'] * 0.69 + b['Claim'] * 0.31).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.to_csv('ins_stack8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
